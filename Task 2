import requests
from bs4 import BeautifulSoup
import csv

def scrape_website(url):
    response = requests.get(url)
    if response.status_code == 200:
        return response.text
    else:
        print("Failed to fetch the webpage.")
        return None

def extract_data(html_content):
    soup = BeautifulSoup(html_content, 'html.parser')
    data = []
    # Example: Extracting all the headlines from a news website
    headlines = soup.find_all('h2', class_='headline')
    for headline in headlines:
        data.append(headline.text.strip())
    return data

def save_to_csv(data, filename):
    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(["Headline"])  # Write header
        for headline in data:
            writer.writerow([headline])

def main():
    url = "https://example.com"  # Replace with the URL of the website you want to scrape
    html_content = scrape_website(url)
    if html_content:
        extracted_data = extract_data(html_content)
        save_to_csv(extracted_data, "output.csv")
        print("Data extracted and saved to output.csv")

if __name__ == "__main__":
    main()
