import nltk
import random
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

# Download NLTK resources
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

# Define responses
responses = {
    "greeting": ["Hello!", "Hi there!", "Greetings!"],
    "farewell": ["Goodbye!", "See you later!", "Farewell!"],
    "thanks": ["You're welcome!", "No problem!", "Anytime!"],
    "about": ["I am a simple chatbot.", "I'm here to assist you.", "I can answer your questions."]
}

# Define stopwords and lemmatizer
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def preprocess(text):
    tokens = word_tokenize(text.lower())  # Tokenization and lowercasing
    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalnum()]  # Lemmatization
    tokens = [token for token in tokens if token not in stop_words]  # Remove stopwords
    return tokens

def generate_response(tokens):
    for token in tokens:
        if token in responses:
            return random.choice(responses[token])
    return "Sorry, I didn't understand that."

def chat():
    print("Chatbot: Hello! How can I assist you today?")
    while True:
        user_input = input("You: ")
        if user_input.lower() == 'exit':
            print("Chatbot: Goodbye!")
            break
        tokens = preprocess(user_input)
        response = generate_response(tokens)
        print("Chatbot:", response)

if __name__ == "__main__":
    chat()
